{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04981af9-f3f8-47f1-ae26-c5315d8b8140",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda env list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6027433-80bd-4b4b-8dcd-ea10da30f462",
   "metadata": {},
   "outputs": [],
   "source": [
    "conda clean -ay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff32771c-85e8-498f-b867-de049ece15d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e172471-a01f-4556-a296-41aef3a239a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/chatglm2-6b\", trust_remote_code=True)\n",
    "model = AutoModel.from_pretrained(\"../models/chatglm2-6b\", trust_remote_code=True).float()\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf7f0d8b-5292-4782-9c1a-64c21989c2ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"你好\", history=[])\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f27da42-942f-4390-bc70-b07ddac08b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "response, history = model.chat(tokenizer, \"晚上睡不着应该怎么办\", history=history)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92e5725a-104f-45e5-997c-32e0e293d570",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# 输入文本\n",
    "input_text = \"中国有什么特色美食\"\n",
    "inputs = tokenizer(input_text, return_tensors=\"pt\")\n",
    "\n",
    "# 如果在 CPU 上运行，确保将 tensors 移动到 CPU\n",
    "inputs = {k: v.to('cpu') for k, v in inputs.items()}\n",
    "\n",
    "# 进行推理\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "\n",
    "# 根据模型的输出结构解包\n",
    "if isinstance(outputs, tuple):\n",
    "    if len(outputs) == 2:\n",
    "        output_1, output_2 = outputs\n",
    "    else:\n",
    "        # 根据具体的输出结构调整\n",
    "        output_1, output_2, *_ = outputs\n",
    "else:\n",
    "    output_1 = outputs\n",
    "\n",
    "# 打印或处理输出\n",
    "print(output_1)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990badd9-a4d6-4ca8-8985-846e3811e2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 提取logits并进行后处理\n",
    "logits = output_1.logits\n",
    "\n",
    "# 获取生成的标记\n",
    "generated_tokens = torch.argmax(logits, dim=-1)\n",
    "\n",
    "# 解码输出，将生成的标记转换为文本\n",
    "output_text = tokenizer.decode(generated_tokens[0], skip_special_tokens=True)\n",
    "\n",
    "\n",
    "print(output_text)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32a4fad6-7e95-4edc-b1d8-19bada14d898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
