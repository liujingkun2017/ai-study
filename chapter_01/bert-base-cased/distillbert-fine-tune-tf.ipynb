{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6dd54cb-7aef-4118-aed2-df2a6c48be15",
   "metadata": {},
   "source": [
    "# **distilbert-base-uncased基于TensorFlow做微调训练**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "421f8631-7c76-4a04-9ee8-9fcc6ad61501",
   "metadata": {},
   "source": [
    "# 1.安装环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88524c9b-5ca2-4541-9be8-47800c19c467",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile requirements.txt\n",
    "datasets\n",
    "pyarrow\n",
    "transformers\n",
    "tensorflow\n",
    "tf-keras\n",
    "keras\n",
    "torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565e0d40-04b4-4326-8e9c-e0c3b4e279b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d672eec8-571c-4e3f-8bf1-5e25b447524c",
   "metadata": {},
   "source": [
    "# 2.加载数据"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18d2911-e694-4092-8e2b-609585875963",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset(\"glue\", \"cola\")\n",
    "dataset = dataset[\"train\"]  # Just take the training split for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33c7ad8d-6059-4d68-9dbb-6e4221825598",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"../models/distilbert-base-uncased\")\n",
    "tokenized_data = tokenizer(dataset[\"sentence\"], return_tensors=\"np\", padding=True)\n",
    "# Tokenizer returns a BatchEncoding, but we convert that to a dict for Keras\n",
    "tokenized_data = dict(tokenized_data)\n",
    "\n",
    "labels = np.array(dataset[\"label\"])  # Label is already an array of 0 and 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ece590d3-854f-4591-8e64-30bdfa53a3a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def tokenize_dataset(data):\n",
    "#     # Keys of the returned dictionary will be added to the dataset as columns\n",
    "#     return tokenizer(data[\"text\"])\n",
    "\n",
    "\n",
    "# dataset = dataset.map(tokenize_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b72289b7-10f2-4480-85fe-9f66ddeab57c",
   "metadata": {},
   "source": [
    "# 3.加载模型准备训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fddab19-9423-400c-937b-e6c0737b191c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# Load and compile our model\n",
    "model = TFAutoModelForSequenceClassification.from_pretrained(\"../models/distilbert-base-uncased\", from_pt=True)\n",
    "# Lower learning rates are often better for fine-tuning transformers\n",
    "model.compile(optimizer=Adam(3e-5))  # No loss argument!\n",
    "# model.compile(optimizer= 'adam' , loss= keras.losses.binary_crossentropy, metrics=['accuracy'])\n",
    "\n",
    "model.fit(tokenized_data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85ad5483-5ab2-45a9-9514-40462fc849aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_dataset = model.prepare_tf_dataset(dataset[\"train\"], batch_size=4, shuffle=True, tokenizer=tokenizer)\n",
    "\n",
    "model.compile(optimizer=Adam(3e-5))  # No loss argument!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7f1f933-cc2f-4fef-8b5b-0273996a77d6",
   "metadata": {},
   "source": [
    "# 4.开始训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8027afed-cc7c-4db2-a552-76409d4b718b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(tf_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49d7e702-cf4e-4eaf-919e-03fc70e27f5b",
   "metadata": {},
   "source": [
    "# 5.测试训练结果"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d6bfec-2e2c-46ca-8bea-dae753a32472",
   "metadata": {},
   "source": [
    "# 6.清理环境"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ea0bbb6-6707-4fad-89e0-148c6ede3649",
   "metadata": {},
   "outputs": [],
   "source": [
    "del model\n",
    "del trained_model\n",
    "del tokenizer\n",
    "\n",
    "del dataset\n",
    "del tokenized_datasets\n",
    "del small_train_dataset\n",
    "del small_eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e8c462-e038-4d51-899f-c070232bfb68",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip uninstall -y -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea8c4ada-3ab2-4692-9e9c-e6b2d39bab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "rm -rf requirements.txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
